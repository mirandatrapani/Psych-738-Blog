---
title: "Concepts: Week two"
description: |
  We delve deeper into a few more papers that take some critical and close looks at previous theories of concepts and finally read about a newer theory proposed by our own professor!
author:
  - name: Miranda Trapani 
    affiliation: CUNY Graduate Center
    affiliation_url: https://gc.cuny.edu/Home
date: 11-19-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Learn more about creating blogs with Distill at:
# https://rstudio.github.io/distill/blog.html

```

<h1>Keil, F. C. (2003). Folkscience: Coarse interpretations of a complex reality. <i>Trends in cognitive sciences</i>, 7(8), 368-373.</h1>

<p>First thoughts: Folk science is an interesting label for a cognition paper. The paper itself seems to be focusing on the not-necessarily-accurate heuristics we use for explanations or expectations in daily life? This is interesting because it seems to be putting emphasis on whether or not we are right in these expectations, but I would say it’s less important whether or not someone is right than how exactly someone got to their conclusion. You don’t have to be right to be thinking. If cognition was only about “how do we get to the right answer?” You could probably say the scientific method and move on. I am still very suspicious of this being called folk science.</p>

<p>Thoughts while reading:<ul>
<li> “laypeople have surprisingly shallow understandings that are masked by an ‘illusion of explanatory depth’, in which they think they understand the world in far more detail than they really do” This is really funny and reminds me of that graph of confidence vs. knowledge of a subject and especially the “mountain of stupidity” or something like that, where basically someone who has a cursory understanding of a subject feels confident they are an expert until they realize how much they don’t know and that confidence comes crashing down, but so many people live on the top of that mt. stupid!</li>
<li> This diagram of a helicopter!!! Yeah man, blades spin and go brrrr really is all I know. Also this paper has those boxes again! I wonder if this is a regularity for this journal. I love it. Trends in cognitive sciences is a good journal!</li>
<li> “Framework theories are meant to provide a conceptual umbrella that gives coherence and sense to all the facts in a domain without filling in any of the details” These theories always give me trouble, and this section did too for the same reason, mostly because these theories by definition need to be quite vague, but in this vagueness I cannot think of any examples unless provided with one with which to apply this theory to see it in action, and thus I have a hard time visualizing how it works, exactly.</li>
<li> “An example can be found in physical structures as simple as paths, which are created by other minds and which relieve later path followers of the cognitive load of navigation” I love this example of essentially “storing cognitive energy for later” in a way as it relies on the cognitive expenditure of others who made the path, which makes some great comparisons and framework for a concept of this sort of collective unconscious almost or group psychology that I think is amazing in many social species like literally any schooling fish or insects like a lot of ant species! However, how exactly this relates to embodied cognition I’m not sure I understand, except perhaps in the way that theory relies on the same neurons involved in perception of a stimulus? I can kind of see a connection there but I’d have to really dig in deep to make it from point a to point b.</li>
<li> Actually my previous thought process reminded me very much of this intuitive folk science discussed here! This intuition informed me of likely avenues to pursue systematically. I could get a rough sense of the relationship but I did know that I don’t have the complete thought, and therefore don’t understand it completely, until I dig in and study more formally. Perhaps, with practice, others could become more attuned and better able to sense how much they really do or don’t know? Knowing how much you don’t know seems like it might be a skill to practice!</li>
<li> “The phenomena of embodied and distributed cognition however do not eliminate the need for central cognition in the mind of the individual. Indeed, in some ways they highlight that need” This final section seems like it is going to highlight the importance of that central cognitive agent like we see in traditional theories</li>
<li> “On what grounds do they assign expertise in that way as opposed, for example, to a water conservation expert or to a manufacturer of swim goggles?” Re: who to ask about why water is transparent. This is an amazing point! These people would for certain have some great insight into this question as well, potentially in a more ecologically applicable way that a chemist or physicist, as their interest will be in bodies of water within the context of the rest of that space, while a chemist or physicist will likely be considering water from more or less a vacuum or at least a less ecologically relevant context such as within the lab or within a theoretical.</li>
<li> “These gists make possible the elaboration of details in a constrained way and the ability to know who knows what around us” The rest of this paragraph is all about why we should ask a chemist before a water conservation expert but personally I would argue that a water conservation expert and a swim goggle manufacturer, these people need to integrate the more defined and isolated fields of chemistry and physics as well as others (that likely will also have an influence on water’s transparency beyond that of the water’s elemental makeup and structure itself) in ways that would actually allow them to offer a more complete answer to that question! Unless of course the original question was simply “what about water’s elemental makeup makes it transparent” in which case… say so! Semantic inferences too are necessary in our daily life, clearly.</li>
<li> “Given that a fully exhaustive understanding in many domains requires an indefinitely deep tracking of causal patterns and regularities, there must be some way in which we know when we have grasped enough to function effectively in everyday life.” This and my discussion above about who to ask about water’s transparency once again I think speaks to how important it is to be interdisciplinary! Learning just enough of a given field to add to that picture of the relevant problem would allow for a truly full picture of that problem beyond what focusing from only one discipline can give.</li>
<li> “The intuitive understandings of the world that do exist in the mind of each individual are all the more remarkable for the power and success that they achieve with such compact and efficient means.“ I appreciate this perspective a lot! </li></ul></p>

<p>Final thoughts: This paper I’m honestly not sure how it fits into the theories of concepts we have been talking about in class. Perhaps a second, quick read through or of previous discussion from class will make that more clear. However I really liked this paper for encouraging different perspectives, which I think is always a really powerful tool if nothing else than for reassuring us of a traditional perspective, as well as for talking about the nuances of daily life and cognition. This paper didn’t quite touch on it but for me brought up thoughts on the importance of ecological validity and interdisciplinary perspectives which I am always excited to think about.</p>

<h1>Fodor, J. (1998) When is a dog a DOG? (Review of Similarity and Symbols in Human Thinking, edited by Sloman, S. A. and Rips, L. J.) <i>Nature</i>, 396, 325-327</h1>

<p>First thoughts: This paper is a review of another paper that seems to be about concepts, of course, and from reading the first paragraph it’s going to be another criticism of the very wide range of explanations we have and the ways in which they contradict each other. Here we are comparing between the pragmatist and the realistic approaches, which again are two new terms for me for these theories. The number of terms to say essentially the same thing alone are confusing to me!</p>

<p>Thoughts while reading: <ul>
<li> Rationalist: to have a concept is to be able to think about the thing that it’s a concept of. TO have a concept of dog is to be able to think about dogs</li>
<li> Pragmatist: To have  concept is to be able to sort things into the ones that the concept applies to and the one that it doesn’t. To be able to sort out the dogs and the not-dogs</li>
<li> Almost all cognitive scientists and theories thus far have fallen under the pragmatist point of view. I guess what they’re saying here is that people have thus far focused too much on categorization without considering the other things a concept might be used for?</li>
<li> “Clearly, the authors are vehemently convinced that there is something that they disagree about, and that it matters a lot which of them is right. But so many empirical, ideological and terminological questions are confounded with the main issue that even a sympathetic reader may wonder whether there is and why it does.” This is really funny but also I’m very interested to hear this author’s explanation of this argument. It reminds me a little bit of what I’ve been saying about how cognition needs to consider their approach more broadly and ask questions about why they are focusing on the things they are</li>
<li> So currently everyone (in this book being reviewed at least) are all in agreement that a concept representation is not a picture but a description of some sort that is a list of features. This list is compared to a list of percepts (aspects of the thing you’re looking at or considering) to see if they match</li>
<li> Ah okay this paper being reviewed was comparing and contrasting definitions and prototypes!</li>
<li> Well I’m already quite comfortable with why concepts aren’t definitions but why they aren’t prototypes is relevant for the paper! So here are the notes on that:<ul>
<li> We can think of an infinite number of things but they all come from finite building blocks: brown cow is brown + cow. Brown cow includes only the things that are at the intersection of brown and cow. This is a compositional system, and also indicates that our concepts themself are systematic.</li>
<li> The prototype theory doesn’t do well with composition because “the prototype for a concept is a specification of what its good instances have in common; and goodinstancehood itself doesn’t compose. What’s a good instance of RED BARN needn’t be a good instance of RED or of BARN”</li>
<li> Essentially, I guess, the prototype theory assumes that red barn has its own prototype, rather than that the prototype for red and barn are able to be “combined” essentially to create red barn</li>
<li> Everyone’s prototype of a red barn would be different, because it would be dependent on which barns they happen to see and in which shades of red. You would have to go SEE red barns to have a concept of a red barn. (The example in the review includes that it is in Idaho but I think just red barn gives the gist)</li>
<li> “there is no particular reason why what is typical of Xs should likewise be typical of an
arbitrary subset of Xs. ‘Prototype’, ‘typicality’ (and the like) are statistical notions, whereas ‘concept’, ‘extension’ and the like are semantic notions. Semantic notions compose but statistical notions don’t. So concepts can’t be prototypes” I’ll have to chew on this a bit to wrap my head around but, I feel like I do understand what this is saying. Prototypes by definition cannot be combined to create new and novel ideas or concepts, because prototypes by definition don’t really offer information on what is meant to be combined exactly?</li></ul></li>
<li> “Maybe experts could tell. (But also, maybe not.) If they can, it’s not because their concept of a cloud determines the answer and mine doesn’t; it’s because they know a lot more about clouds and contrails than I do.” It seems to me that their concept of these things then would be richer due to all the extra information they know about these things. Where in these theories has there been the space to allow for a quality gradient in concepts, I wonder? Is that something cognition scientists have thought about? Or is it something they write off as beyond the role of concepts? If a concept includes the nature of the object in question in some way, wouldn’t further knowledge about that nature of that object be right there in the concept itself?</li></ul></p>

<p>Final thoughts: This review wasn’t about dogs as much as I expected but it was a good read! I think it did a very good job talking about the assumptions of these theories of concepts and asking questions about whether or not they are relevant. When I think about embodied cognition as well I wonder how it might fit into theories that are less focused on categorization and more on simply thinking about the things in the concept. I feel like I’m finally beginning to understand concepts and the arguments for and against the different theories, and those arguments implications!</p>

<h1>Prasada, S. (2016). Mechanisms for thinking about kinds, instances of kinds, and kinds of kinds. <i>Core knowledge and conceptual change</i>, 209-224.</h1>

<p>First thoughts: A chapter about concepts by our professor!  I am hoping that this chapter will talk about each theory in turn and the holes in each, partially for this assignment but also because these comparisons are what really solidify the similarities and differences in my mind to prevent confusion and also to help me keep all this weird and somewhat arbitrary terminology straight!</p>

<p>Thoughts while reading:<ul>
<li> So here we seem to be focusing rather than on categorization (the conditions under which a given concept applies), but in how exactly the concept represents things as “one of indefinitely many instances of a kind” and “provide the means for thinking about the kind as such” which I think means our experience of using a concept, and how exactly it works to allow us to think about things (or kinds, for this chapter)</li>
<li> So we’re going to learn about type-token mechanisms (I believe that means predication?) and the highlight of this mechanism is two things:<ul>
<li> The mechanism captures the key characteristics of standard approaches to conceptual representation in principled manner</li>
<li> the mechanism provides a principled basis for formally distinguishing psychologically significant kinds of kinds</li></ul></li>
<li> So basically an instance of a kind must have two components: the representation of that kind and the representation of that specific instance</li>
<li> In order to think about even a single instance of something you need to employ the same mechanism that exists for thinking about kinds in general (a generic vs. nongeneric reference)</li>
<li> There must be k-properties to distinguish a kind (nongeneric, the type) from any other kind. These properties support formal explanations that are explanations by reference to the kind of thing something is (dog has 4 legs because it is a dog), support normative expectations (by virtue of being a dog, you would expect it to have 4 legs) and are generally expected to be present in instances of the kind (think of dogs, most of the ones you thought of probably had 4 legs!)</li>
<li> What seems to be important about these k-properties is that they are not an all or nothing thing, it seems like. Together they characterize and individuate an instance as a given kind, but there seems to be room for certain instances to be missing some, such as 3 legged dogs. I suppose then the natural question is: how many does an instance need to be determined a certain kind? Why that many? Is it different for different kinds? Why? Of course these become questions of categorization, don’t they!</li>
<li> Unlike traditional approaches to concept representation (definitional, prototype, theory, exemplar), the generative type-token mechanism described here captures key characteristics of the standard approaches to conceptual representation in a principled manner. It proposes a generation of representations of instances of kids, which accounts for the kind of phenomena that the exemplar theory explains. Like the prototype theory, this mechanism allows for instances which lack some of their k-properties, as well.</li>
<li> Because k-properties are represented as aspects of being the relevant kind, this model directly supports formal explanation of these properties (I believe that is the “a dog has 4 legs because it is a dog” thing from before)</li>
<li> It can also support teleological and causal explanations by identifying properties that have a non-accidental connection to the kind. I’m not completely sure what this means, I think I might have missed this above. </li>
<li> There are count nouns which are things where instances are distinct by virtue of their being the kinds of things they are (dog, tree, etc) and there are mass nouns which instances are distinct for other reasons (water, sand, wood!) The generative type-token mechanism can make this distinction, although I’m not sure how</li>
<li> Polysemous refers to kinds that can be considered in two distinct ways based on their concrete and abstract matter, such as books wherein you can have two of the same book or two books that are different.</li>
<li> Not all books/reading literature however are able to be distinguished by their abstract content. All newspapers are the news!</li>
<li> Illustrative example: Sally pet the dog and Sue did too, clearly the same dog. Sally read the book and Sue did too, clearly the same book but not necessarily the same COPY of the book, possibly two distinct copies. Sally read the newspaper and Sue did too, neither the brand nor individual copy if the same brand is clear here.</li>
<li> Kinds contain indefinitely many instances that need only be numerically distinct. This has been repeated a few times but bears saying clearly in my notes.</li>
<li> However these instances can be similar but still have differences! Thus we have subkinds. (Like breeds of dogs? Types of scientists? But what makes these subkinds and not kinds? Are dogs not just a type of canine? A type of mammal? A type of animal? A type of living creature?)</li>
<li> A kind can contain subkinds in this model but does require it. </li>
<li> Subkinds should have these k-properties but realize them in different ways. All dogs bark but different breeds bark differently. All dogs have 4 legs but different breeds differ in the proportion and shape of the legs</li>
<li> So subkinds involve qualitative distinctions at a finer granularity than the kind mechanism itself</li>
<li> White bear is not the same as polar bear. A polar bear is a way to be a bear, a white bear is something to be in addition to being a bear. Here inlies where subkinds and adjectival descriptions of an instance differ.</li>
<li> A subkind can have a property not found in the k-properties for the kind! Dalmatians have spots, but not all dogs have spots.</li>
<li> Of course we would cite Chomsky to state that non-human animals have no lexical concepts!</li>
<li> The end we are saying it is possible that this model exists in a way that does not change as we grow, more similarly to the core knowledge theory, and less like the causal explanation theory. However unlike the core knowledge theory, this theory put forth here is not expected to be found in animals as there is no evidence that animals have lexical concepts capable of both abstract and concrete perspectives as we do, and as featured in this model.</li></ul></p>

<p>Final thoughts: I like this chapter as an exploration of a new theory that seems to me to make a good deal of sense! It seems to account for many issues identified in earlier ones, and by comparing and contrasting those earlier ones with each other and this one here, it makes them easier to distinguish now. I do wish that this chapter had attempted to incorporate a little more what we know from work on embodied cognition with regards to patterns of brain activation, the areas at play, and thus relations to other brain functions and skills.</p>
