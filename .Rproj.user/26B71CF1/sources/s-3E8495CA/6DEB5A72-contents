---
title: "Decision Making: Week one"
description: |
  This module focuses on the foundational Signal Detection Theory. The basics of it, using it, and most excitedly, all of the other things it is useful for besides discriminating across sensory stimuli!
author:
  - name: Miranda Trapani 
    affiliation: CUNY Graduate Center
    affiliation_url: https://gc.cuny.edu/Home
date: 11-24-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Learn more about creating blogs with Distill at:
# https://rstudio.github.io/distill/blog.html

```

<h1>Stanislaw, H., & Todorov, N. (1999). Calculation of signal detection theory measures. <i>Behavior research methods, instruments, & computers,</i> 31(1), 137-149.</h1>

<p>First thoughts: Decision making and signal detection theory at first confuse me a bit as being considered related, as my first impression of decision making would be more along the lines of intentional or conscious decision making, the systems we use to decide things and so on. However signal detection theory, which I am somewhat familiar with from my basic processes class during my Masters, instead refers to our thresholds for stimuli detection and discrimination. I suppose perhaps this will involve borrowing the framework of stimuli detection thresholds and instead applying a decision making threshold theory?</p>

<p>Thoughts while reading:<ul>
<li> This is illustrated in Figure I, where the decision variable (measured in arbitrary units) has a mean of 0 and a standard deviation of 1 on noise trials.” A z score!</li>
<li> The key use of SDT: “The major contribution of SDT to psychology is the separation of response bias and sensitivity.” This separation of the factor of response bias (tendency to say yes or no) and sensitivity, the perceptual origins of SDT</li>
<li> “Thus, sensitivity can be quantified by using the hit and false-alarm rates to determine the distance between the means, relative to their standard deviations.” This is done by dividing the distance between the means by the standard deviations. So d’ is the standard deviation of the mean for a given response rate, or I guess like a z score, because as we have seen above the decision variable is standardized. Unless I am mistaken and there is some sort of pooled or averaged standard deviation calculation going on to get the accurate denominator</li>
<li> The measure d’ is unaffected by response bias and exclusively measures sensitivity if two assumptions are met: <ul>
<li> First: The signal and noise distributions are both normal </li>
<li> Second: The signal and noise distributions have the same standard deviation. That answers my question above!</li></ul></li>
<li> So I would assume in order to use responses to a given task and compute these scores you would first have to ensure their normality and then transform them to fit on a normal distribution with a mean of 0 and a standard deviation of 1? Wait no, only a standard deviation of 1. Wait, if the standard deviation is always 1, as indicated above, then isn’t the d’ value purely the difference in means?</li>
<li> “A' typically ranges from .5, which indicates that signals cannot be distinguished from noise, to 1, which corresponds to perfect performance. Values less than .5 may arise from sampling error or response confusion; the minimum possible value is O” I guess this is a simple percentage correct responses?</li>
<li> The ROC area (Receiver operating characteristic) is another way of measuring responses, unlike measurements used anova like d’, this one doesn’t rely on the assumption that the signal and noise distributions have the same standard deviation in response rate. This kind of measurement works for yes/no and for rating tasks </li>
<li> “Thus, d is found by subtracting the z score that corresponds to the false-alarm rate from the z score that corresponds to the hit rate.” Ah, I understand better now why it isn’t simply the difference in means! Although again, once you have transformed this data fit on a z score graph, it is indeed just the difference in means. Got it!</li>
<li> This paper is really good at math! The statistics and the explanation of the equations and better ways to write them is really impressive, I’m sure this is a big part of why this paper is so important. It is not lost on me that this level of comfort with statistics is particularly an asset in this field, as psychology people tend to be a little mathphobic!</li>
<li> “Adding terms to the series increases accuracy, but, in practice, a limit is imposed by round-off errors.” I wonder if computer software advances in the past 20 years have made the use of power series for conversions between z scores and probabilities more viable as you can hopefully avoid rounding altogether.</li>
<li> “Regardless of the approach used for the (phi) and (phi)-1 functions, problems may arise when the hit or false-alarm rate equals 0, because the corresponding score is (negative infinity) Similarly, a hit or false-alarm rate of 1 corresponds to a z score of (positive infinity)” That makes sense, it is hard to find an algorithm (method?) that can be extrapolated to extremes</li>
<li> “SPSS lacks the sign function, so the statement ABS(H - F)/(H - F) is used instead.” I find this a really clever trick for a really funny problem</li>
<li> “The five pairs of hit and false-alarm rates that result from this procedure are listed in Table 5.” So should these be done for every difference between signal and noise? Or I supposed these are only yes/no tasks. Are true signals present at every task? Or does it not matter?</li>
<li> “Thus, researchers who are primarily interested in sensitivity may wish to avoid yes/no tasks altogether and rely, instead, on forced-choice or rating tasks.” I think I followed the reasoning behind this in the previous two paragraphs, none the less I will definitely highlight it here as a key takeaway, although it’s not the point of the paper</li></ul></p>

<p>Final thoughts: I honestly expected this paper to be a very difficult read as my prior experience with SDT has admittedly not been the most interesting of concepts or studies. However, this wasn’t bad! The section on its possible applications and their variety was valuable, and this paper is a great one to have in my repertoire for how detailed it goes into the many varying ways of computing signal detections, the different measurements I mean, when to use what, as well as information on how to run them in various programs (although I imagine that section is now quite outdated) and explanation of equations and why to use certain ones!</p>

<h1> Litvinova, A., Herzog, S. M., Kall, A. A., Pleskac, T. J., & Hertwig, R. (2020). How the “wisdom of the inner crowd” can boost accuracy of confidence judgments. <i>Decision.</i> 7(3), p 183-211.</h1>

<p>First thoughts: In reading the abstract this is essentially a paper about how to improve one’s own accuracy individually by asking your “inner crowd” which is essentially yourself twice? Of course not literally about how to do that, but about how this is a phenomenon that seems to work under a certain circumstance, when you are already guessing above chance without doing it, it seems. Already that makes sense, perhaps this is a sort of polarizing mechanism. If you are scoring below chance then you start to score consistently wrong, indicating an opposite response criteria to that desired. Would make sense! </p>

<p>Thoughts while reading: <ul>
<li> So here is what I should be getting some solid impressions on from this paper: “ confidence (metacognitive decisions; resolution vs. calibration), wisdom-of-the-crowds effect, averaging vs. maximizing, consensuality, dialectical bootstrapping, "kind" vs. "wicked" environments/stimuli/contexts”</li>
<li> “Representative samples of general knowledge items lead to better calibrated confidence in comparison to selectively sampled items, yet they do not fully eliminate miscalibration” So basically, when people make confidence judgements their flaw is more in the information samples that they use to make these assessments and less on whether they have assessed their own knowledge well.</li>
<li> I am obsessed with this entire introduction basically saying “when people are encouraged to or taught how to think critically, they make more accurate judgement calls”</li>
<li> Kind items: items for which the majority agree on the right answer</li>
<li> Wicked items: itms for which the majority agreed on the wrong answer</li>
<li> For these two above, particularly wicked items, bring up why you might want to average confidence judgements rather than maximize them if you’re trying to optimize accuracy</li>
<li> An important note on averaging confidence judgements: “When the knowledge sources underlying the aggregated judgments are distinct, averaging improves the ability of confidence judgments to discriminate between correct and wrong decisions (i.e., resolution) but compromises the correspondence
between subjective and objective probabilities (i.e., calibration), whereas under shared knowledge sources, averaging solely improves calibration by canceling out random error (Ariely et al., 2000; Wallsten & Diederich, 2001)”</li>
<li> “systematic study of the boundary conditions for the success of averaging and maximizing and delineate under which conditions one strategy would have an edge over the other.” In a round about way, this is kind of a paper on knowing what you know! </li>
<li> For correct judgements, if the two assessments (both low and high confidence) are both correct, it’s hard to tell whether maximizing or averaging provide a better score. However when the low confidence assessment is wrong and the high confidence is correct, maximizing is always better than that of averaging. For incorrect judgements (with wicked items), averaging is always better for getting the correct judgement.</li>
<li> “In sum, as the probability P of the high-confidence-choice being correct increases, increasing the weight on the high confidence choice is beneficial. In contrast, as P decreases, decreasing the weight on the high-confidence choice is beneficial” where P is the Brier score (essentially an average of the confidence scores with 0 being the best possible and 1 being the worst possible score. See graphs and explanation on page 5 and 6)</li>
<li> Some important considerations for this algorithmic finding: “However, not all combinations of (a) the probability P that the high-confidence choice is correct; (b) the confidence CH in this high-confidence choice; (c) the confidence CL in the other, low-confidence choice; and (d) whether the high- and low confidence choices are the same or not, are equally likely in practice)</li>
<li> “diversity in judgments is a key requisite for the wisdom-of-crowds effect” Intuitively makes sense, redundant assessments (both assessments are very similar) the wisdom-of-crowds effect is less pronounced</li>
<li> “Maximizing improved the Brier score in kind environments (i.e., p(C)  .5), for example, by .065 points for r  0 and p(C) .9, but impaired the Brier score in wicked environments (i.e., p(C)  .5), for example, by .09 points for r  0 and p(C)  .2. Furthermore, maximizing outperformed averaging only once p(C)  .6 but not yet for p(C)  .5. As redundancy (r) increased, the sizes of these beneficial and harmful effects both decreased.” Given the definition of wicked items, this makes a lot of sense this polarizing effect we see with maximizing. Of course if you’re more confident in the wrong answer, you will be more wrong if you maximize your judgements! Also, of course redundancy would minimize these effects, the potential difference between the judgement outcomes also shrinks.</li>
<li> “calibration (i.e., the extent to which subjective and objective probabilities match) and resolution (i.e., the extent to which confidence discriminates between correct and wrong decisions, irrespective of calibration).” Just some definitions</li>
<li> “Averaging had an effect on resolution similar to that of maximizing, but it performed better on two other measures of the decomposition (bias and scatter) and therefore outperformed maximizing for wicked items.” Makes sense!</li>
<li> The four major insights of the simulation study described in part above:<ul>
<li> Averaging judgments resulted in improved overall accuracy irrespective of the wickedness of the items</li>
<li> For wicked items, maximizing resulted in poorer accuracy than sticking to the first judgement but in better accuracy for kind items</li>
<li> Maximizing outperformed averaging only once items were answered correctly 50-60% of the time or more, modulated by redundancy scores. This means a kid item is necessary but not sufficient for maximizing to outperform averaging, a novel finding to this study</li>
<li> Confidence correlated with how strongly the majority agreed on an answer, not wit the correctness of the decision per se (hence the wicked item observations)</li></ul></li>
<li> This was using a model however so there are chances of this model/simulation not being an accurate depiction of human behavior, thus prescriptive recommendations based on these may not be meaningful in a more ecologically relevant context (actual confidence judgements made by humans within a given context)</li>
<li> This second study purposefully asked participants (actual people this time) to use a dialectical bootstrapping approach (the consider-the-opposite technique) for the second judgement, this also reduced redundancy in confidence judgements, and this was to see if this would improve accuracy when using the averaging technique</li>
<li> Their final analysis was looking at 3 different studies, in the third of these they saw that the dialecti- I’m so confused by my note. Is study two or three here the one using the dialectical bootstrapping approach? Here on page 18 it says study 3 however I have in my notes here study 2. This paper is huge. This final comparison of 3 studies could have been its own separate paper</li>
<li> Ok I went back and understand now. There is study 1 (described above) and study two, which is made up of 3 smaller studies: two reanalysing data from other papers, and a third one which is a new work on human participants and uses the dialectical bootstrapping approach!</li>
<li> The first two studies analyzed here in study two were for the purpose of determining whether the results of the simulation in study one did in fact generalize to human samples. They found consistent results in that averaging confidence judgements from the same person improved overall accuracy where as maximizing harmed overall accuracy even in environments with relatively few wicked items</li>
<li> “Our theoretical and empirical results suggest that averaging should be the preferred strategy to harness the wisdom of one’s inner crowd. The reason is that the robust averaging strategy, relative to the more fickle maximizing strategy, can boost accuracy of confidence judgments while requiring less
knowledge about the kindness and wickedness of the items the decision maker faces.” The overall statement from this paper!</li></ul></p>

<p>Final thoughts: This paper was quite the marathon! Luckily it was a pretty easy read for the most part, until I got to the part where they were describing the three different studies they looked at in study two. Overall, this paper was pretty interesting in it’s careful and methodological assessment of what some could essentially call a heuristic, these confidence judgments! I love the applicability of this to daily life, maybe I’ll do better when playing “Who Wants To Be A Millionaire” now.</p>


<h1>Roets, A., Schwartz, B., & Guan, Y. (2012). The tyranny of choice: A cross-cultural investigation of maximizing-satisficing effects on well-being. <i>Judgment and Decision Making,</i> 7(6), 689.</h1>

<p>First thoughts: </p>

<p>Thoughts while reading: <ul>
<li> Here are the things that I need to keep in mind while reading: “satisficing vs. maximizing, regret/buyer's remorse, individual and societal differences in these decision approaches”</li>
<li> “People on either side of this dispositional continuum have been labeled satisficers and maximizers, respectively, and the latter group is expected to be more vulnerable to the problems that arise from an excess of choice.” So Satisficers adopt a “good enough” approach and aren’t bothered/influenced by number of options because as long as one passes their threshold of being a good option they are happy with it. While with maximizers they are more vulnerable to regret/buyer’s remorse because they strongly need to feel that they have the best option, so as options out there increase and it becomes infeasible to know all information about each one to make the best, most informed decision, they become upset, dissatisfied with their lives, less optimistic, etc</li>
<li> My first question is again one of individual differences; do people take on different strategies for different decisions? What kinds lead to which strategy? What other traits correlate to one’s propensity to use a given strategy?</li>
<li> So essentially they are going to compare maximizers reactions to choices in Western societies such as the US to those in China where personal choice/individualism is a less salient determiner of happiness.</li>
<li> “the adaptive form of perfectionism is often associated with a variety of positive outcomes and higher well-being, whereas the maladaptive form is associated with negative outcomes and lower well-being.” No wonder, maladaptive perfectionism just sounds like a symptom or expression of some anxiety or mood disorder! </li>
<li> “this link is considerably weaker or even absent in nonwestern societies (i.e., China).” I’m not sure that China has this wildly different opinion of maximizing options as one might think. At the very least, I would argue that there is as much individual variability in the population as there is in western societies, however when I think about the kinds of choices that people might have multiple options for such as schools, cars, apartments, clothing, and food, all of these decisions offer numerous upon numerous options in China as well. If you are seeking a society where everyone has minimal options for food, clothing, shelter, vehicles, and many other day to day decisions, China is not it! They even have three major cell phone companies to choose from. I have less wifi options here at home in the US than I did in China!</li>
<li> So their scale for how much of a maximizer a person is is this Maximizing Scale which is an aggregate of three facets, the one of interest here is the High Standards facet because HIgh Standards per se the research is split on whether high standards actually is associated with worse well being the way it has been seen with maximizing strategy in general (see the perfectionism comparison above for an explanation on why this might be)</li>
<li> God the wage demographics of the three different sample sets is incredibly interesting. A mere 2.8% of Chinese participants stated they had a “more than average” income. Is this cultural (not willing to admit/it being rude to claim you make a lot of money) or a sign of the widening class gap in China I wonder?</li>
<li> Relationship of maximizing and society with well being:<ul>
<li> What is the purpose/role of the dummy-coded society variables? What does this mean?</li>
<li> The relationship between maximizing and well-being is significantly different in China compared to Europe and the U.S., and there is no significant difference between the U.S. and Europe. </li>
<li> There was a negative relationship for the U.S. and Europe and no such relationship for China (no relationship at all!)</li></ul></li>
<li> Relationships of maximizing and society with regret: <ul>
<li> Maximizing was associated with higher levels of regret in all three societies</li>
<li> There was a significant main effect of maximizing and there was one of society. I don’t know why but this wording has been confused on the implication/what this result means! I guess just that these two influence each other? Or these two were influential in the regression for all three measures.</li>
<li> Between China and Europe there was a nearly significant interaction between maximizing and society, and for China and the U.S. it was small and significant</li></ul></li>
<li> Relationships of regret and society with well being:<ul>
<li> Does this mean controlling for well being? Semi-partial correlations perhaps? I wish I understood this terminology just a bit better, I would like a visual aid of the variance spread or something like that</li>
<li> For this one, there was a significant main effect of regret, but no significant main effect for society when comparing across the countries, although there was a significant interaction between regret and society for China versus both Europe and the U.S. However, it sounds like this interaction is just from the regret influence and not the society? Not sure what the implications are of this, hopefully the discussion clarifies</li>
<li> “As can be seen in Figure 3, regret had a negative relationship with wellbeing after controlling for demographic variables in both the U.S. and Europe (Beta = −.43, and Beta = −.51, both p <.001), whereas the relation in China was much weaker (Beta = −.18, p < .05).” Tired of typing these out, this will be easier to reference later</li></ul></li>
<li> Mediation analyses:<ul>
<li> Basically what these results indicate is that the difference between China and the Western societies compared is that the influence of maximizing is not that China has a different relationship with maximizing and regret but a different relationship between well-being and regret. Maximizers do regret more regardless of society, but only in Western societies does this regret lead to less well-being.</li>
<li> A final analysis was done that showed this as well (“between Europe and China, the significant interaction effect of maximizing and society in step 2 dropped substantially and was rendered only marginally significant in Step 3” Step 3 is when the interaction between regret and society was also considered) (For the U.S. the significant interaction between maximizing and society completely disappeared when controlling for the influence of regret in step 3)</li>
<li> “The interaction between culture and regret in step 3 approached significant for Europe versus China and [was] significant for the U.S. versus China” Another reiteration of that above</li>
<li> They also bootstrapped the mediation analyses and found that “the total effect of maximizing on well-being in Europe stems from the combination of a direct and an indirect effect through regret, whereas in the U.S., the total effect of maximizing on well-being is entirely attributed to their indirect link” Which is a potentially interesting nuance of these societies that I wonder what they will say about</li></ul></li>
<li> Relationships at the facet level: <ul>
<li> Here they compared using the Maximizing scale across the three facets that make it up due to previous research identifying that the High Standard portion may not be a good measure in that it doesn’t hold the same relationship with well being as the other facets of the Maximizing scale</li>
<li> They used Europe as the reference society as they were also interested in comparisons between the two western societies</li>
<li> They found a significant effect on well-being from the interaction of society and facet scale for all three facets between Europe and China. Between Europe and the U.S. there was only a significant interaction on well being for the interaction of the High Standard facet with society, not the other two facets.</li>
<li> There was a significant negative slope between well-being and HIgh Standards facet in Europe but not in the U.S.</li>
<li> All three facets had a relationship with regret in all three societies, with interactions with society for each scale</li>
<li> Through bootstrapping they also found significant indirect effects in Europe for all three facet scales, as well as a direct effect for Alternative Search and Decision Difficulty (the other two facets of the Maximizing scale), and in the U.S. these were similar</li>
<li> “no total effect of High Standards was found in the U.S., because the detrimental indirect effect of High Standards on well-being was countered by its direct effect, which showed an opposite sign” This means according to them that “High Standards are associated with increased regret, and therefore with
lower well-being, but they also have a positive association with well-being that is independent from their association with regret.” Which is that same issue discussed and posited above!</li>
<li> In looking into this, there was a bit of a different relationship between the High Standards facet and the two kinds of perfectionism (negative and positive) in that for the negative kind of perfectionism the U.S. relationship with High Standards was a bit smaller correlation than in Europe, although this difference wasn’t significantly different</li>
<li> I think personally the most important distinction is this finding: “Positive perfectionism also
showed a small negative relationship with well-being in the European sample but, most interestingly,
a positive association was found in the U.S. sample”</li></ul></li>
<li> The associations between the High Standards facet and perfectionism indicate “the Maximizing High Standards facet itself has both an adaptive and a maladaptive aspect or meaning.” as well</li>
<li> “In particular, it seems that, in the U.S. sample, the modest positive influence of the dominant positive aspect of high standards (i.e., positive perfectionism) counters the strong negative influence of the less dominant negative aspect of high standards” A reiteration/explanation of the reason for the difference in relationships between High Standards and perfectionism in the U.S.</li></ul></p>

<p>Final thoughts: This paper was pretty interesting! I liked the comparisons between China and Europe and the U.S., although I still feel that the authors claim that China has less options for certain decisions was not necessarily a well researched one. I think that one thing they should have delved into more is what kinds of decisions exactly these results are relevant for, and why. I am also curious how these differing maximizing and satisficing strategies influence other behaviors. Are maximizers less likely to try new things because they worry it will be a bad choice compared to what they already do/enjoy/have/eat/etc? That might be interesting to look at!</p>
