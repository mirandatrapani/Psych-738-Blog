---
title: "Embodied Cognition: Week one"
description: |
  I read about a topic I only just recently discovered, with surprisingly more focus on the critiques of the theory than the theory itself!
author:
  - name: Miranda Trapani 
    affiliation: CUNY Graduate Center
    affiliation_url: https://gc.cuny.edu/Home
date: 10-27-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Learn more about creating blogs with Distill at:
# https://rstudio.github.io/distill/blog.html

```

<h1>Barsalou, L. W. (2008). Grounding symbolic operations in the brain's modal systems.</h1>

<p>First thoughts: Since I first learned about the idea of embodied cognition a few weeks ago I have been extremely interested and excited for this module! This first reading seems to be a chapter from a textbook, which I’m sure will be a great introduction to the concept.</p>

<p>Thoughts while reading:<ul>
<li> Reasons why classic symbolic approaches (language like symbols and operations) to implementation of symbolic operations (problem solving, predictions, decision making, planning, metacognition etc) have been critiqued:<ul>
<li> They are not sufficiently statistical, neural net approaches have been developed to remedy this</li>
<li> They are not grounded in perception, action, and introspection. For this reason other have argued that higher-order cognition is grounded in the brain’s modal systems (those listed above? and what exactly is meant by higher order cognition? If cognition is hierarchical in this way, what is the top level and how does it differ/act as the “starting point” so to speak of concepts and thought?)</li></ul></li>
<li> Some say that classic symbolic operations are irrelevant to higher cognition (which is which though?</li>
<li> Grounded theories of cognition: symbols whose content are extracted from images, thus bound to regions of images and establish “type-token mappings,” are manipulated and integrated to construct structured images that implement complex symbolic propositions. ABstract concepts come from introspection, perceiving internal mental and bodily states in the context of external situations and developing these image based representations of them</li>
<li> Several questions so far: my initial understanding of embodied cognition was that involved the input of the body itself (eg. your perception of things influences and is influenced by your bodily relation to it). This does seem to be the case in that that’s part and parcel for your environment playing a role, but I am lost in the weeds of exactly what this means compared to more traditional systems that seem to be syntactically based. Which systems are these that we are referring to? Is there no language/syntax based cognition in this approach? How does approach hold up when looking at the cognition of blind people? Also, what are type-token mappings, what does that mean? Does this system expect to find a sort of homunculus of cognition in the brain, this consideration of the body that I expected? I’ll need a refresher on the homunculus from a neuroscience perspective to better understand how the two work together if so!</li>
<li> “These states represent sensory-motor information about the perceived category member, with some (but not all) of this information producing conscious experience.” There’s the body part, got it!</li>
<li> Introspection in the context of this paper: perception of modal states in internal systems (motivational systems, affective systems, cognitive systems)</li>
<li> For The transduction of amodal symbols from modal states in standard cognitive architectures: “Use of transduced symbols to represent the meaning of a word (Panel B). See the text for further description” is there a symbol for every word? Isn’t that just language? There’s a symbol for every word in chinese. In rereading the figure, this seems to be the model for traditional approaches which are more language based</li>
<li> Grounded theory of knowledge: instead there are conjunctive units in hierarchically organized association areas which light up fully when seeing the thing in question, and are then simulated (the brain attempts to recreate the image, but only partially so these areas are not used to the same extent as during the initial capture)</li>
<li> This simulations can be mental images, neural reenactments of modal states (which happen during perception of the different features of the stimulus), but regardless the idea is that the representation of the knowledge of something is grounded in the modal states themself rather than the amodal symbols transduced from them (those syntactically representations).</li>
<li> Other grounded assumptions: when looking at this system there are 3 misunderstandings:<ul>
<li> 1: It is viewed as an instantiation of classic empiricist theories. This apparently has to do with experience vs. genetically encoded simulations. Here they argue that there is likely a neural architecture of processing particular categories (objects, events, and introspective states), which are particularly strong association areas in the brain. This is a divide I have no experience with so I’m not sure the argument for or against either side.</li>
<li> 2: This architecture is a recording system incapable of interpretation: This critique makes sense to me. However, interpretation is at the heart of application of symbolic operations (the symbolic modal states of introspection mentioned earlier)</li>
<li> 3: This architecture only captures knowledge from perception of the external world. To me this assumption relies on the previous one, and so disproving one disproves the other. </li></ul></li>
<li> “The rapidly accumulating findings across these diverse literatures indicate that the higher cognitive processes engage modal systems frequently and robustly.” an important concept to hold close </li>
<li> “This experiment offers a demonstration that the brain's modal systems become active during cognitive processing” When looking at pictures of food but only for the purpose of identifying matches, the gustatory and reward systems still lit up in the brain. The question now is why, what are these systems doing in this scenario? Are they epiphenomenal or are they implementing symboli operations associated with taste and reward inferences about the foods shown?</li>
<li> “One possibility is that activations in modal systems underlie symbolic operations. Rather than amodal symbols implementing these operations, simulations implement them.“ Simulations in this case are things like the memories of those depicted foods? Do memories count here?</li>
<li> Perceptual Symbol Systems theory (PSS): implements concepts and their interpretive functions using image content as basic building blocks. The brain develops concepts this way: encountering different instances of the same category activate similar neural patterns in feature systems (encountering the wheels, steering wheel, engine for cars, it has been shown these are all correlated, although what that means we’d have to read the reference to find out). These similar patterns tend to be captured by similar populations of conjunctive neurons in the brain’s association areas. Across experiences, those relevant neurons integrate the modal features of a category (is this meaning the sensations across the senses of each stimuli?), making a distributed multimodal representation of it (the different aspects visually, sight, touch, etc all go together)</li>
<li> These multimodal presentations are called simulators to PSS, they are basically the “concept” in more traditional cognition theories. Hey, things are starting to make sense!</li>
<li> “When attention focuses repeatedly on a type of object in experience, such as cars, a simulator develops for it. Analogously, if attention focuses on a type of action (driving) or on a type of introspection (fear), simulators develop to represent it as well.” Kind of poetic!</li>
<li> “Because selective attention is flexible and open-ended, a simulator develops for any component of experience that attention selects repeatedly.” makes sense!</li>
<li> Once the simulator is established, a single simulation can only ever stimulate a subset of the contents at once (for example, a simulation in the car simulator might be a sedan, a sports car, a jeep, etc)</li>
<li> These simulators are what make symbolic operations possible. If concepts can do symbolic operations, then simulators can. The 3 classic symbolic functions are predication,conceptual combination, and the representation of abstract concepts.</li>
<li> Predication through PSS:<ul>
<li> You need to be able to distinguish type from token. The simulator - simulation distinction naturally implements the type-token distinction (performs the same function?) This also helps me understand better what type-token mapping means. Tokens are individual instances of the type! Exemplars!</li>
<li> These combinations (token to type) can produce predications because the proposition that a given token/simulation belongs to a type/simulator is a proposition that can be wrong (a car! nope that’s a small truck)</li>
<li> These predications are infinite, thereby producing an interpretative spin, indefinitely many true and false interpretations are possible.</li>
<li> Predication: not prediction like I thought! it means “n logic, the attributing of characteristics to a subject to produce a meaningful statement combining verbal and nominal elements.” basically being able to categorize and name things?</li></ul></li>
<li> Conceptual combination in PSS:<ul>
<li> The simulator for above, essentially, can be combined with the simulators for whatever two objects are in relation to one another, because the simulator for above will be an aggregate of all the different kinds of ways “x is above y” can exist.</li>
<li> “Infinitely many other conceptual combinations can be implemented by simulating different types of objects or events in the regions of the above simulation, thereby expressing related propositions, such as ABOVE (jet, cloud), ABOVE (lamp, table), and so on” More examples of the flexibility</li>
<li> “Because simulators represent components of situations and relations between components, their simulations can be combined into complex, multicomponent simulations” The main point. Can be done for previously experiences combinations or novel ones.</li></ul></li>
<li> Representing abstract in PSS:<ul>
<li> Abstract concepts are like truth or thought, less known about but understanding them as well as concrete concepts (bird) can help produce increasingly sophisticated forms of intelligent computation.</li>
<li> Recently thought to represent introspective states. The more introspective content in the concept, the more abstract. Typically relate introspective states to situations and events. (Eg. intend relates from introspective states to events causally)</li>
<li> For this reason they provide an opportunity to look at metacognition. People perceive their internal states through introspection, they perceive their motivations, affective states, etc. Simulators can be developed to represent the internal world, through introspection.</li>
<li> Simulators formed of internal states through introspection, therefore, can be simulators of abstract concepts.</li></ul></li>
<li> Study to determine predication in this modal system required people to determine whether objects in a block matches a descriptor of some kind (a type-token test). It was found that “These findings suggest that participants simulated the property being assessed on each block (e.g., loud). As each name of an object in the subsequent block was read (e.g., "drill"), participants simuLtted the object and assessed whether it contained the simulated property (e.g., is a drill loud).”</li>
<li> Another study on the same topic: people assess whether objects were 4 things, each an assessment through a different sensory modality. When predicating each object on each modality, the associated brain region with sensations of that modality lit up. Indicating properties being predicated are grounded in simulation. (That recreation of the experience thru the same area lighting up)</li>
<li> Property switching experiments used because if you’re switching from one sensory modality (hey! is that the modal of a modal system?) to another so if simulator-simulation is capable of predication, it should take longer to respond for the first trial that switches modalities. This is what they found!</li>
<li> A follow up study found that “More importantly, he showed that the switching effect is not the result of shifting from one conceptual domain to another.” referring to a study by Marques in which “Conceptual domains were similarly held constant for artifacts (for the target property telephone-ring, the same versus different context properties were clock-tick tack versus mirror-reflect).” Indicating that the switching effect happens in… all switching contexts? I’m not sure, I’m confused here.</li>
<li> It’s not associative strength in general, another study used pairs that were different modalities but similar associations and the different modalities led to slower response speeds.</li>
<li> “Switching costs suggest that these modal activations are not merely epiphenomenal but underlie the symbolic process of predication itself. Because switching modalities induces a cost in predication, it appears that modal processing plays a causal role in predication. If modal processing were epiphenomenal, the amodal symbolic operations central to predication should be unaffected by a change in modality” the bread and butter of all those studies' findings.</li>
<li> “participants simulated properties when predicating them of concepts, and that the shapes affected the predication process rather than being epiphenomenal” More important findings</li>
<li> “Most notably, the perceptual variables explained significant amounts of unique variance after variance attributable to the linguistic and expectancy variables was removed” Oh I know this in stats! They compared the residuals after finding the portion of variance due to linguistic and expectancy variables. </li>
<li> For concept combination they (Barsalou, the author, in another study), asked half of their participants to think of just “lawn” and the other to think of “rolled up lawn” For concept combinations, the rolled up lawn should think of dirt and roots more because this are more salient in the simulations. These kinds of content in simulators are called “occluded properties” and are not something amodal theories of conceptual combination predict</li>
<li> “Wu and Barsalou however, observed occlusion effects for novel combinations, suggesting that participants simulated their referents to perform conceptual combination.” because if it was simply amodal then for example “glass car” shouldn’t readily give engine because the novel glass car hasn’t yet been associated with engine, however this was what they found.</li>
<li> This is not the case for a revealing modifier with all concepts, just where that revealing modifier actually would reveal something, reinforcing that the simulation is modal (a mental picture kind of thing) </li>
<li> “These findings suggest that people use simulation to represent abstract concepts. When given the word for an abstract concept, people simulate the situations in which the concept occurs” the bread and butter of the portion on experiments showing the PSS works for abstract concepts as well.</li>
<li> “Much like humans, nonhumans have attentional systems that could allow them to isolate regions of experience and store categorical knowledge about these regions in simulators. By establishing simulators in this manner and organizing them situationally, nonhumans could simulate anticipatory inferences that support feeding. reproduction, and so on.” my favorite theories of cognition work easily for nonhumans too!</li>
<li> “Consistent with evolutionary theorists (e.g., Donald, 1993), symbolic capabilities could have increased dramatically once language evolved to control the simulation system in humans” this makes so much sense to me!</li></ul></p>

<p>Final thoughts: This paper isn’t exactly what I expected it to be, but neither is embodied cognition! I look forward to the next two papers to hopefully solidify my use and understanding of the terminology, what is correct to use, and where embodied cognition fits into the field and understanding of cognition as a whole.</p>

<h1>Mahon, B. Z., & Hickok, G. (2016). Arguments about the nature of concepts: Symbols, embodiment, and beyond. <i>Psychonomic bulletin & review,</i> 23(4), 941-958.</h1>

<p>First thoughts: This paper seems like another review type of paper focusing on the way that symbols do or do not play into embodied cognition. The “symbolic representation” view seems to be perfectly at odds with embodied cognition, so I expect this to be another paper on how the latter works to better represent cognition. Perhaps, as this paper is 8 years more recent than the previous, this will be a review of the field’s growth mostly since then.</p>

<p>Thoughts while reading:<ul>
<li> “Bilateral lesions to lateral occipital–temporal cortex could lead to impairments in recognizing objects but no difficulty performing grasping and reaching movements to the same objects. Other patients presented with the reverse behavioral dissociation after lesions to posterior parietal cortex: impaired object-directed reaching and grasping, despite intact object identification” Interesting example of category-specific deficits associated with a brain region. An example of support for the two-visual (ventral/dorsal) systems model. I remember that from neuroscience in undergrad!</li>
<li> “The sensory/functional theory refers to the idea that dissociations among different
classes or categories of information arise because of damage to modality-specific brain systems, and that there are high correlations between certain categories and certain modality specific systems.” Another good theory to have the definition of around.</li>
<li> Sensorimotor systems are engaged during conceptual processing, which led to development of the embodied cognition or grounded cognition hypothesis</li>
<li> “the embodied framework emphasizes the format in which conceptual information is represented (i.e., in a modality-specific or sensorimotor format, a multisensory format, as opposed to in an amodal format).“</li>
<li> “Within the perceptual symbol system framework, conceptual processing is embodied or grounded because conceptual content is, at least in part, reaccessed sensorimotor information—concepts are not an additional level of representation that is abstracted away from sensorimotor systems and represented in a stand-alone manner from those sensorimotor systems.” This makes so much sense! I think this theory is really starting to make sense to me, in a greater image way as well as the actual nuts and bolts of it</li>
<li> Important aspect of embodied theories: conceptual format is not arbitrary, as it is determined by the content of the concept: For instance, sensory concepts have a sensory format, and action concepts have a motor format.”</li>
<li> Classic or disembodied theories believe that the format of conceptual representations is not constrained by what those concepts are about, concepts are amodal in format. One issue with this is that it would mean there is an arbitrary relation between concepts and wah they represent.</li>
<li> “The point is there is no inherent tension between abstract, symbolic, amodal representations and grounding” I think this paragraph on the way amodal systems use amodal symbols to represent concepts is not necessarily at odds with a modal (grounded/embodied) system because embodied systems too require a transduction of perceived stimulus into the brain representation (considering how the retina transforms the perception of a visual stimulus across retinal ganglion cells)</li>
<li> “In summary, the principal evidence for the view that concepts are represented (at least in part) by sensorimotor information— the embodied cognition hypothesis—is the observation that conceptual processing leads to the activity of modality-specific systems.” Yes! That makes sense! And is something definitely seen very much and talked about in neuroscience, as well as regarding mirror neurons like the paper did before.</li>
<li> “the conceptual information that is involved in naming or recognizing pictures does not involve the sensorimotor information that is damaged in patients who can no longer effectively use tools” but they can still see it? I’ve never used a buzz saw before but I’m pretty sure I can point one out.</li>
<li> “The theory championed by Kosslyn, and many others, argued that visual imagery occurs
over a representation that is visual in its format—that a mental image is a picture in the brain-- as such (and only as such), would visual mental images inherit and exhibit the metrical
properties of an actual physical image.” You know, I wonder if the camps of people who are for “visual imagery is a picture in the brain” and “visual imagery is NOT a picture in the brain” are made up of groups of people who are and are not capable of visualizing pictures in their head. This is not something everyone can do, judging by discussions across social media recently in which each individual talks about how they “think.”</li>
<li> “The fact that vision, and perhaps visual mental imagery, is laid out in a retinotopic manner on the manifold of the cortex doesn’t mean that the format of retinotopic visual processing
is in any interesting sense “imagistic”” Unless of course that’s how your own brain works would you suppose such a thing!</li>
<li> “Turning our theories ‘inside out’ and empirically studying their bridging assumptions promises to be one of the next great adventures in the study of concept representation in the brain.” I think I still don’t fully understand what a bridging assumption is.</li></ul></p>

<p>Final thoughts: In terms of understanding, this paper pretty quickly got away from me. It spent a long time talking in depth about other theories and work that supports them, which is good! It also spent a lot of time comparing the two theories very closely, which is also good! However it used a lot of terminology I was unfamiliar with, and referenced papers results or overall influence without explaining what the paper did, likely under the assumption anyone reading would already know the paper. I know I am not an embodied cognition paper’s target audience, but all of this meant that I was pretty confused reading through it. This is clearly my overarching critique of papers, however. I just wish that more papers took a moment to explain in clear terms the main vocabulary they use, and less often referred to important concepts as acronyms, as I will quickly forget what the acronym means and thus it will lose meaning to me.</p>

<h1> Mahon, B. Z. (2015). What is embodied about cognition?. <i>Language, cognition and neuroscience,</i> 30(4), 420-429.</h1>

<p>First thoughts: Judging from the previous reading by this same author as well as the abstract, this author seems very critical of the embodied cognition theory instead in favor of a new, integration between embodied and disembodied cognition (modal and amodal systems) I believe? Or this author is actually strongly in the “amodal representation of concepts” camp, which I guess would make the previous paper very interesting as it is 5 years later. I wonder why we were asked to read this one third!</p>

<p>Thoughts while reading: <ul>
<li> According to this article so far, the question we should really be asking is not why do sensorimotor system activate during recollection of related experiences, but more along the lines of how does the conceptual system disengage from the sensorimotor system, and what is the mechanism that gates information flow within the system? </li>
<li> “If the issue concerns ‘where understanding occurs’, rather than whether concepts are represented in a modality-specific format, then the discussion has devolved into a matter of
terminology. ‘Understanding occurs’ in the classroom, at a desk, on a piece of paper and with a pencil” This seems like a brush off to me.</li>
<li> I think I like the embodied cognition argument because it makes sense to me. I understand neuronal activation while thinking about/considering a concept in the same area of the brain associated with first hand sensations with that concept very easily. These descriptions of the amodal model only kind of make sense to me.For example: “Any (seeming) transparency between the meaning of concepts and their instantiation in the sensory/motor system is independent of whether the format of a concept is amodal or modality specific. The reason why is because the format of a concept and the format of the representations with which it is connected in the input and output systems are independent empirical questions.” Why? How do we know this? How did we decide this? I understand that thinking about sofa makes “soda” produce” more quickly than “table” but why does that evidence lead to these assumptions?</li>
<li> Now arguing that weak embodiment theories are actually disembodied theories, this sounds to me like this author is the one getting caught up in terminology!</li>
<li> “if the issue of whether or not concepts are represented in a modality-specific format has been resolved, then there is no longer any debate about embodiment (and no longer any embodiment).” I also don’t understand this jump. They claim that there is no difference between a “weak embodied” concept and a “disembodied” concept. The argument seems to be that the disembodied concept has room to account for conceptual processing leading to sensory/motor activation, but what is the explanation if not that conceptual representations are sensorimotor in nature?</li>
<li> The main argument according to them is that a modal system offers no possibility for abstract concepts to exist, and that any suggestion is “logically secondary to the principal application of the embodied cognition hypothesis to concrete content” THEN goes on to say “if it cannot explain concrete content, then it will fail for abstract content” which is a completely unrelated statement to the entire rest of the paragraph. However, I don’t understand why considerations of abstract content have to be “logically secondary,” what that means, and why that’s a bad thing?</li>
<li> “To quote Binder and Desai (2011): ‘conceptual deficits in patients with sensory-motor impairments, when present, tend to be subtle rather than catastrophic’” Okay, this definitely makes sense though!</li>
<li> “By the same token, it is also important to note that there are a number of observations
from patient studies that indicate sensory/motor impairments can affect conceptual processing (e.g., Bonner & Grossman, 2012; Kiefer, Sim, Herrnberger, Grothe, & Hoenig, 2008; Trumpp, Kliese, Hoenig, Haarmeier, & Kiefer, 2013). That means that one cannot go to the other extreme and assume that sensory/motor processes are irrelevant to conceptual processing” For sure, that makes sense! So why is weak embodiment such a bad thing, then?</li>
<li> “The substance of the embodiment debate, which used to be about whether the
format of concepts is abstract or modality-specific, has morphed into a discussion about whether activity spreads from amodal representations to sensory/motor representations and back again.” I Just feel like this entire paper is arguing “okay, embodiment exists to some extent, therefore it doesn’t exist!” Which like… huh?</li>
<li> “To summarise: In the measure to which proponents of the embodied cognition hypothesis support a version of weak embodiment, the only coherent alternative is the view that there is no spread of activation between amodal concepts and sensory/motor systems. Thus, weak embodied theories and their alternative are in agreement on the issue on which they purport to disagree: the format of conceptual representation.” But didn’t you say earlier that weak embodiment argues that concepts are at least partially represented by modal systems? Is that what disembodied cognitions argues for as well? Due to the evidence that we now know this is clearly the case? But the name and argument previous to that evidence claimed that was the incoherent alternative up above? So really, isn’t it that the disembodied argument has disappeared and is now no longer functionally different from the weak embodiment argument? Again, is this paper arguing over terminology? It seems to me like disembodiment said “this never happens!” and embodiment said “this always happens!” and now we find out it happens sometimes/somewhat, and this entire paper is arguing that disembodiment should be the one that gets to claim a victory that neither previous theory actually deserves. Both argue the same thing, so therefore both are disembodiment. Why can’t both be embodiment? I’m so confused but also so annoyed!</li>
<li> “An alternative theory argues that the knowledge that fires are red is not stored via the systems that perceive red, but adjacent to those systems.” I just don’t understand why it can’t be both! Is it because there is not enough “room” in the brain to account for “knowing something” (storing a given fact) in brain multiple times? It is well established there are infinite potential concepts, infinite potential facts. There is certainly no room for considering them all once! So why then is it unacceptable to imagine that the same information could be represented in multiple ways in the brain?</li>
<li> “An embodied theory of conceptual processing has a very different self-stated goal than an embodied theory of conceptual representation” Okay, this distinction must be where I am getting confused and angry!</li>
<li> “If information is represented in a modality-specific format, then it is ipso facto also about that modality (i.e., its content is modality-specific). But, if information is about a given modality (e.g., information is about the visual properties of objects, or about object manipulation), then it may or may not also be assumed to be represented in a modality-specific format” I’m not sure I understand the difference here.</li>
<li> “The only formulation of the embodied cognition hypothesis that is coherently different from a so-called ‘disembodied’ account of concept representation is the proposal that concepts are modality-specific in their representational format.” I’m not so sure that this is the argument, though. Isn’t this the strong embodiment argument that concepts are ONLY modality-specific? And does that really suppose that embodiment believes that concepts can only exist in a single modality in the brain? Surely when you think of a car the information is represented across modalities. I think of the sensation of seeing a car, hearing it, smelling, touching it. This is multiple modalities. </li>
<li> “there is nothing embodied about such a theory because the embodied hypothesis is a claim about representational format, not representational content” Overall this argument kind of made sense again until this line, these lines drawn in the sand of what is x y and z when all three are referring to things that are so intricately related (representational format vs representation content vs. representational processing). I understand very broadly why they are different but at the same time overall I really cannot help but feel that this article is attacking this theory on a technicality</li>
<li> “have argued that questions about the format of conceptual representations are at best premature, and at worst, theoretically underdetermined: premature because we need a theory of how activation spreads before inferences about representational format can be drawn with any confidence, and underdetermined because once a theory of dynamics is adopted, both embodied and disembodied theories predict sensorimotor activation during conceptual processing.” This isn’t really my interpretation of the argument, but I do feel that there is a lot to be learned neurophysiologically before cognitive sciences can make the kind of leaps they are trying to. Of course my determination of this is mostly how confused I get reading papers, but I just know that if there were concrete studies to read to explain and support these theories, they’d make so much more sense to me! So my agreement of this is based purely on what I need, personally, to understand these concepts. </li>
<li> “It is the independence of thought from perception and action that makes human cognition special – and that independence is guaranteed by the representational distinction between concepts and sensorimotor representations” and “The fact that there is flexibility in the sensory/motor manifestations of meaning indicates that sensory/motor processing cannot be what constitutes meaning” I have to chew on these thoughts in the final few paragraphs a bit more, but I am a bit confused. Is the implication that across contexts sensorimotor perception/activation changes, but conceptual processing remains the same? I cannot understand how that works, as it is my understanding that from sensation to perception, where the sensorimotor cortex is activated, is the absolute first region in which a stimulus enters the brain, and all processing from there is downstream. I understand that multiple types of stimuli can fall under the same concept and receive the same “processing” whatever that might entail, but  the sensorimotor perception itself is what determines which concept it falls into, isn’t it? </li></ul></p>

<p>Final thoughts: I disliked a few things about this paper. I didn’t like that it seemed to try to catch an alternative theory on a technicality, claim they were actually the same, and then at the end introduce new issues and an argument of the paper that didn’t fit what I interpreted the content to be about. I know I’m not an expert here, but I’ve been taking psychology classes for a long time now and surely if my idea of what a paper is about and the author’s idea of what it is about don’t align, I mean maybe I’m missing something big or maybe this paper is just confusing! </p>
